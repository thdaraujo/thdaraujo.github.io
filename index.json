[{"content":"You want to add bootstrap, or jquery, or react, or any other javascript library/tool/framework the cool kids are using now to your Rails App. üï∂Ô∏è\nYou search for a tutorial. First, they tell you to import some file on javascript/application.js.\nLater, you come accross another tutorial that tells you to use Webpacker.\nEventually, you realize that Rails 6 comes both with Sprockets AND Webpacker set up by default. ü§Ø\nIn case you don\u0026rsquo;t know, Sprockets and Webpacker are two completely different ways to compile and serve static assets. So now, you\u0026rsquo;re asking these questions:\n Why do I need to add stuff to javascript/application.js? What is Sprockets doing? What is Webpacker doing? How do Sprockets and Webpacker interact? Which one gets executed first? Wait, now I need to learn Webpacker and javascript modules all of a sudden? Do I even need both? I just want to write some ruby code!  You probably don\u0026rsquo;t need to have both, unless you have a pretty good reason and a solid understanding of these tools.\nWhy does Rails 6 comes with Sprockets and Webpacker? Because legacy applications and older gems still use Sprockets to serve assets such as javascript, CSS, and images. This was done to add backwards compatibility.\nHowever, you don\u0026rsquo;t need to have Sprockets. Most apps can just use Webpacker, as it can serve javascript, CSS, even images and fonts. That\u0026rsquo;s the direction that Rails is going.\nOur Elixir friends are doing exactly that: the Phoenix framework uses plain-old Webpack by default.\nIf you want to go in the direction that Rails is going regarding static assets, just stick to Webpacker. Gems are moving away from the asset pipeline and you can easily find npm packages to suite your frontend needs.\nIf you\u0026rsquo;re convinced and ready to ditch Sprockets in favor of Webpacker, here\u0026rsquo;s a list of good tutorials for new and small apps, up to huge legacy ones:\nNew or small Rails Apps: keep it Webpacker-only If you\u0026rsquo;re creating a new Rails app, do youself a favor and just skip generating anything related to Sprockets:\n$ rails new . --no-sprockets If you have an existing app, this guide is perfect for people who are in a hurry or not doing anything crazy on the frontend side of things. It\u0026rsquo;s good for newer Rails 6 apps.\nRails 6 with Webpacker in app/assets (and no Sprockets)\nMedium-sized apps: Move everything over to Webpacker This guide explains how to migrate everything over to Webpacker - CSS, Javascript, fonts and images. It applies to Rails 6.\nGoodbye Sprockets. Welcome Webpacker\nThis other tutorial is very similar but goes over a couple of extra things and gives some tips about Polyfills and CircleCI deployment.\nMigrating From Sprockets to Webpacker\nHuge Legacy Apps: Keep Sprockets Working While Migrating to Webpacker Impossible? Maybe not! Check out this example of a successful migration.\nThis is an in-depth post explaining how a team gradually switched from Sprockets to Webpacker on a larger Rails App. They had to support both Webpacker and Sprockets to maintain backwards compatibility. They go over the challenges and how they were able to solve the issues that popped up.\nTheir approach had 3 distinct phases:\n preparation migration cleanup  It\u0026rsquo;s a good read when you\u0026rsquo;re not sure if you should make the move or not. Planning for this type of migration is something that you should definetely consider, depending on the complexity of your frontend and the legacy gems you still use.\nThe best way to do such a big change is by gradually moving assets to Webpacker while keeping the existing asset pipeline intact until you get rid of Sprockets completely, as this process can take a while.\nAnd make sure you have good tests!\nHow we switched from Sprockets to Webpacker\n","permalink":"https://www.thd.codes/posts/how-to-remove-sprockets-from-rails/","summary":"You want to add bootstrap, or jquery, or react, or any other javascript library/tool/framework the cool kids are using now to your Rails App. üï∂Ô∏è\nYou search for a tutorial. First, they tell you to import some file on javascript/application.js.\nLater, you come accross another tutorial that tells you to use Webpacker.\nEventually, you realize that Rails 6 comes both with Sprockets AND Webpacker set up by default. ü§Ø\nIn case you don\u0026rsquo;t know, Sprockets and Webpacker are two completely different ways to compile and serve static assets.","title":"Examples on How to Remove Sprockets From a Rails Application"},{"content":"Did you always want to help an open-source project like Ruby on Rails, but never got started?\nMany people have the interest of contributing to open-source, myself included. I\u0026rsquo;ve done a couple of small contributions, but nothing fancy.\nIt\u0026rsquo;s a little intimidating, right? You\u0026rsquo;re not part of the group of contributors and you don\u0026rsquo;t really know where to start. You see 800 open issues, but which one should you pick?\nI\u0026rsquo;ve had those feelings as well. But if you never get started, you\u0026rsquo;ll never learn what is really needed. Besides that, the rails community is super friendly and helpful, you don\u0026rsquo;t need to be scared.\nEverybody\u0026rsquo;s got to start somewhere. Better now than later. And you can just learn as you go.\nThat\u0026rsquo;s what Stefanni and I have been doing. We just decided we wanted to start contributing to open-source and we picked our first issue.\nWe started a project called Open Source Thursdays.\nWe\u0026rsquo;re doing a livestream every thursday on our youtube channel showing what we\u0026rsquo;re doing and what we\u0026rsquo;re learning.\nThe goal is to show the real life of working on a new codebase: lots of googling, stumbling around, debugging, making lots of mistakes, reading docs and learning in real-time. We\u0026rsquo;ve been having lots of fun!\nLast week, we went over a couple of Rails issues, and some of them looked promising. There was no open issue labeled as \u0026ldquo;good for beginners\u0026rdquo;, and we didn\u0026rsquo;t really want to work on an issue that was too simple (such as changing documentation), so we tried a different approach.\nWe looked for issues that had:\n a good description of the bug had reproduction steps written down had no open pull request available we could understand the problem without needing too much context about the codebase  We selected a couple of issues, and then decided to pick this one: Active Storage Disk Service NoMethodError: undefined method `rails_disk_service_url' related to ActiveStorage.\nThe first step was to try and reproduce the error by following the reproduction steps, which was possible.\nWe were able to run a Rails app that is just a single ruby file by using the bundler/inline feature.\nThis script will automatically install any missing gems, require the gems you listed, and then run your code. Pretty cool, right?\nThen we tried one of the solutions that someone commented, but we were not able to fix the problem. So we created a gist showing what happened and asking for feedback and more information. That was the end of the livestream!\nDuring the week, we got some more answers and ideas. One of the problems was that we were using the wrong ruby version (2.7 vs 3.x), and that fixed our problem.\nNow have a little bit more context (from this comment and this other comment).\nWe\u0026rsquo;ll start writing some code to implement a fix. That\u0026rsquo;s going to happen this Thursday, so stay tuned!\nCheck our youtube channel if you\u0026rsquo;re interested!\n","permalink":"https://www.thd.codes/posts/picking-a-rails-issue/","summary":"Did you always want to help an open-source project like Ruby on Rails, but never got started?\nMany people have the interest of contributing to open-source, myself included. I\u0026rsquo;ve done a couple of small contributions, but nothing fancy.\nIt\u0026rsquo;s a little intimidating, right? You\u0026rsquo;re not part of the group of contributors and you don\u0026rsquo;t really know where to start. You see 800 open issues, but which one should you pick?","title":"How to pick your first Rails Issue and start contributing to Open-Source"},{"content":"You need to change production data. You know that doing it manually is unsafe and will definetely cause lots of trouble, like corrupting all you customer\u0026rsquo;s data.\nHow else should you do it?\nYou might be spending a lot of time asking yourself these questions:\n Is there a proper rails way to change data in production? Should I run data and schema modifications in one database migration? Should I run rake scripts in production to modify data? Should I use a specialized data migration gem?  You will get different answers depending on whom you ask. Some people will tell you that changing data with a database migration is an anti-pattern and migrations should only contain schema changes.\nBut isn\u0026rsquo;t the whole point of a migration to be a good way to define a point-in-time transition of database structure or data, using code?\nIf you have a larger application or a mission-critical system, you should be careful about how you update production data, as this can lead to downtime and big problems. This post won\u0026rsquo;t cover this scenario.\nHowever, if your app is still relatively new and small, this post is for you. Here\u0026rsquo;s how you can use data migrations to change production data without shooting yourself in the foot.\n1. Schema changes and data changes are like water and oil: they shouldn\u0026rsquo;t hangout together Write data manipulation code in separate Rails migrations and give them proper names. NEVER change schema and data in the same migration.\nAnother tip: consider separating complicated migrations and code changes in multiple pull requests you can merge and deploy separately. That way you can incrementally change the database and catch errors or rollback more easily.\n2. Stick to plain old SQL, if you can Careful when using models in migrations. It\u0026rsquo;s better to just write data manipulation as Arel or plain SQL queries and not use models at all, because if you change the model, your old migrations might break.\nSQL is independent from ActiveRecord model\u0026rsquo;s definitions, queries won\u0026rsquo;t trigger callbacks, and most importantly: any future code changes to a model won\u0026rsquo;t cause you a world of pain.\nWell-written SQL queries can be really fast. Just be careful and make sure you\u0026rsquo;re updating the right things.\nAlways ask yourself: Am I missing a where statement here somewhere?\nSee this nice example from Discourse of a simple data migration:\nclass MigrateAtDesktopBookmarkReminders \u0026lt; ActiveRecord::Migration[6.0] def up DB.exec( \u0026lt;\u0026lt;~SQL, now: Time.zone.now UPDATE bookmarks SET reminder_type = NULL, reminder_at = NULL, updated_at = :now WHERE reminder_type = 0 SQL ) end def down # add some code to revert this migration, if possible end end 3. Strong Migrations (optional) Consider adding the strong_migrations gem to your project and following its suggestions as much as possible. These guidelines will help you catch unsafe migration code during development and teach you some good practices.\nPay special attention to the warnings related to adding indexes and default values to existing columns, as this can cause downtime.\nDoing these things will put you in a good spot and make your life easier in the future.\n","permalink":"https://www.thd.codes/posts/rails-data-migrations/","summary":"You need to change production data. You know that doing it manually is unsafe and will definetely cause lots of trouble, like corrupting all you customer\u0026rsquo;s data.\nHow else should you do it?\nYou might be spending a lot of time asking yourself these questions:\n Is there a proper rails way to change data in production? Should I run data and schema modifications in one database migration? Should I run rake scripts in production to modify data?","title":"How should I change production data on a new Rails application?"},{"content":"My wife and I are launching the greatest podcast in the world and a new site called hexdevs!\nWe\u0026rsquo;ll talk about how to start a business, and how to get better at your craft.\nWe want everyone to be more confident, successful, and smarter, so if you want to become an awesome dev, listen to our podcast and sign up for the mailing list!\nAnd stay tuned!\n","permalink":"https://www.thd.codes/posts/podcast/","summary":"My wife and I are launching the greatest podcast in the world and a new site called hexdevs!\nWe\u0026rsquo;ll talk about how to start a business, and how to get better at your craft.\nWe want everyone to be more confident, successful, and smarter, so if you want to become an awesome dev, listen to our podcast and sign up for the mailing list!\nAnd stay tuned!","title":"hexdevs podcast"},{"content":"The EMR (Elastic Map Reduce) service on Amazon has some nice packages that come pre-installed, and one of them is Apache Zeppelin, which is a Jupyter Notebook interface for Spark.\nZeppelin has interpreters for spark, pyspark, spark-sql and others, but if you want to run spark-sql code on a PostgreSQL database, you need first to install the JDBC interpreter and add some extra configuration to Zeppelin.\nThe JDBC adapter supports a wide variety of database engines, and it allows you to configure multiple database connections, which makes data exploration much easier.\nThe generic JDBC interpreter supports these databases:\n PostgreSQL MariaDB MySQL Redshift Apache Hive  In the next section, I\u0026rsquo;ll explain how to install and configure the JDBC interpreter on Apache Zeppelin.\nInstalling the JDBC Interpreter on Zeppelin When you\u0026rsquo;re creating your EMR cluster on AWS, on the Software Configuration step, make sure to include these applications: Zeppelin 0.8.1, Spark 2.4.0. You can also go to Advanced Options and check all the applications you need. Also, make sure to add an EC2 key pair so you can connect to it with ssh.\nThen, after your cluster is running, connect to it via ssh:\n$ ssh -i [path-to-your-ec2-keypair].pem hadoop@[some-address].compute.amazonaws.com Then run this command to install the jdbc interpreter:\n$ sudo /usr/lib/zeppelin/bin/install-interpreter.sh --name jdbc \u0026gt; Interpreter jdbc installed under /usr/lib/zeppelin/interpreter/jdbc. Restart Zeppelin by running these commands:\n$ sudo stop zeppelin \u0026gt; zeppelin stop/waiting $ sudo start zeppelin \u0026gt; zeppelin start/running, process 24434 PROTIP: this step can also be run as a bootstrap-action for convenience. EMR allows you to define a bash script that is run when creating your EMR cluster and it will be executed when each node is started, once on the master node and once on all the slave nodes. You can define bootstrap actions before creating the EMR cluster.\nNow, in order to run a query, you need to configure the Zeppelin interpreter. To access Zeppelin notebook, first you need to open an ssh tunnel to your EMR cluster and configure a proxy that will safely access the cluster through the ssh tunnel.\nConnecting to EMR with FoxyProxy 6.x In order to access the web tools on your EMR cluster, you need to configure the Web Connection. Go to Amazon EMR \u0026gt; Clusters \u0026gt; click on the cluster you just created, then click on Enable Web Connection. This will explain how to set up an ssh tunnel and configure foxyproxy.\nTo set up the tunnel on port 8157, run:\nssh -i ~/emr-key.pem -ND 8157 hadoop@[master-public-dns-of-your-cluster] Then you need to configure a proxy management tool. The tutorial description on amazon explains how to set up foxyproxy, but this is not up-to-date because foxyproxy doesn\u0026rsquo;t support XML configurations anymore, so you\u0026rsquo;re gonna need to use a json config. To do that, copy this configuration example here and save it as foxyproxy-config.json.\nThen, follow these steps:\n Install the FoxyProxy add-on, then click on the FoxyProxy icon on the top right corner of firefox click on Import On the first section Import Settings from FoxyProxy 6.x (current version), click on Browse Select foxyproxy-config.json and confirm. You\u0026rsquo;re gonna see a new proxy configuration on the foxyproxy list called EMR SOCKS Proxy. Enable the proxy by clicking on the foxyproxy icon on the top right corner of your browser and select Use proxy EMR SOCKS Proxy for all URLs (ignore patterns)  Now you should be able to access any of the web application interfaces running on your EMR cluster, like Zeppelin, Ganglia, and YARN. You can see a list of them here.\nTo access Zeppelin, go to http://[master-public-dns-of-your-cluster]:8890/.\nConfigure Database Connections  On Zeppelin, go to Interpreters http://[master-public-dns-of-your-cluster]:8890/#/interpreter. Click on + Create to configure a new Interpreter Give it a name (like jdbc) to be used on your notes as %jdbc Choose JDBC as the interpreter group Configure the connection properties, like default.url, default.password, default.user and default.driver (if needed) to access your database.  The interesting thing about the JDBC interpreter is that you can define multiple connections to any different type of database by using a prefix instead of the default one and defining an appropriate driver, as described here. As an example, I wanted to connect to three different PostgreSQL databases, so I configured my connections as following:\nDatabase DB1\ndb1.url -\u0026gt; jdbc:postgresql://db1-url:5432/db-name1 (string) db1.password -\u0026gt; ******* (password) db1.user -\u0026gt; db1user (string) db1.driver -\u0026gt; org.postgresql.Driver (string) Database DB2\ndb2.url -\u0026gt; jdbc:postgresql://db2-url:5432/db-name2 (string) db2.password -\u0026gt; ******* (password) db2.user -\u0026gt; db2user (string) db2.driver -\u0026gt; org.postgresql.Driver (string) And so on. The JDBC interpreter uses the driver and the connection details to access the database in a generic way, so it\u0026rsquo;s pretty easy to connect to any kind of database and use the same querying interface. In order to use a different connection on your notebook, you define the interpreter and add a prefix, like so:\n%jdbc(db1) SHOW TABLES; %jdbc(db2) SHOW TABLES; Running Queries To use the generic JDBC interpreter, create a new zeppelin note. Then click on Settings (Interpreter Binding) and enable/bind the JDBC interpreter to your note. You just need to enable jdbc.\nThen, to use the interpreter you just created, create a new paragraph, and define the interpreter and the connection prefix you want to use:\n%jdbc(prefix) SELECT * FROM tableA; In my case:\n%jdbc(db1) SELECT * FROM client; Now you have a simple way to connect and explore different databases in a very simple way. Hope you find it useful!\n","permalink":"https://www.thd.codes/posts/jdbc-on-emr-zeppelin/","summary":"The EMR (Elastic Map Reduce) service on Amazon has some nice packages that come pre-installed, and one of them is Apache Zeppelin, which is a Jupyter Notebook interface for Spark.\nZeppelin has interpreters for spark, pyspark, spark-sql and others, but if you want to run spark-sql code on a PostgreSQL database, you need first to install the JDBC interpreter and add some extra configuration to Zeppelin.\nThe JDBC adapter supports a wide variety of database engines, and it allows you to configure multiple database connections, which makes data exploration much easier.","title":"Generic JDBC Queries on EMR Zeppelin"},{"content":"I\u0026rsquo;ve been building the data infrastructure for a project and I needed to efficiently query, merge, process and clean terabytes of structured data and then index hundreds of millions of documents on elasticsearch.\nThe problem is that querying and joining data on a RDBMS like Postgres is very painful when you have more than low terabytes of data. You\u0026rsquo;re going to spend a huge amount of time tuning your database, reading query plans, adding indexes, sharding, and slowly moving data around until you have something decent that take hours, days, maybe weeks to run. Trust me, I\u0026rsquo;ve been there.\nBesides, indexing millions of documents on elasticsearch is also complicated, you have to spin up lots of new nodes even when you don\u0026rsquo;t really need to scale your cluster right away. In my case, I just needed fast and efficient bulk indexing, searching and filtering don\u0026rsquo;t need to be super fast because data velocity is not a problem yet, but volume is. Tuning bulk indexing and optimizing memory usage on elasticsearch is not fun either.\nBut I\u0026rsquo;m an impatient developer, and I need my stuff right now. The only way to do that is by liberating the data and moving it to a large hadoop cluster.\nNowadays, with Amazon EMR (Elastic Map Reduce) and spot instances, it\u0026rsquo;s really, really cheap to just spin up a cluster with hundreds of nodes and run your big data processing job in a very cost-efficient way. And you don\u0026rsquo;t even have to manage it, EMR has templates with pre-installed tools, like Apache Sqoop, Spark and Hadoop.\n  light speed is too slow, we\u0026rsquo;re gonna have to go right to Ludicrous Speed!\n  Why you should consider this approach? It\u0026rsquo;s really cheap! I have a couple of jobs that are memory-heavy, and I run them on Spark. One of them runs on a cluster with 41 r4.2xlarge instances, each one of them has 8 vCPUS and 61GB of memory, so that\u0026rsquo;s a total of 328 CPUs and 2.5Tb of memory. Neat, huh?\nThey\u0026rsquo;re all spot instances that I can rent and pay $0.14 per hour, so running the cluster costs $6 dollars per hour :moneybag::moneybag::moneybag:. It may look like a lot, but here\u0026rsquo;s the cool thing about it: my job runs in about 30 minutes. After that, I just kill the cluster.\nIt\u0026rsquo;s really fast! Compared to the process we had before (SQL, logstash, some elixir code, and some bash scripts), I calculated it would take more than a month to run the whole thing and index all the data (yeah, it\u0026rsquo;s very slow). And this is assuming that one server would even be able to handle it (I bet it wouldn\u0026rsquo;t), and I\u0026rsquo;m not even considering the time it would take me to fix and optimize the whole process just to make it run properly and consistently.\nAmazon even has a service right now called AWS Glue that abstracts away the whole cluster thing, so you just pay by the hour to run your Spark jobs, pretty much like Lambda. And if you prefer Google cloud, they also have some options too.\nIn my case, I can spin up the EMR cluster and let it crunch some terabytes of data while I brew my coffee, and spend just $6 dollars. That\u0026rsquo;s a huge improvement for an impatient dev like myself. After all, time is a very precious thing.\nSometimes running Hadoop and Spark is overkill, but for this problem it was a no-brainer: one person can build the whole map-reduce job and manage the cluster easily, and just move the final data to S3 when finished. So if you have a problem like that, you should seriously consider if a proper big data tool could be a better solution than your current one.\n","permalink":"https://www.thd.codes/posts/elasticsearch-indexing-with-spark-overview/","summary":"I\u0026rsquo;ve been building the data infrastructure for a project and I needed to efficiently query, merge, process and clean terabytes of structured data and then index hundreds of millions of documents on elasticsearch.\nThe problem is that querying and joining data on a RDBMS like Postgres is very painful when you have more than low terabytes of data. You\u0026rsquo;re going to spend a huge amount of time tuning your database, reading query plans, adding indexes, sharding, and slowly moving data around until you have something decent that take hours, days, maybe weeks to run.","title":"Fast ElasticSearch Indexing with Apache Spark on EMR (overview)"},{"content":"An interesting quote about the unexpected effects of actions and the limitations of rationality and the planning fallacy:\n A net set up to catch fish may snare a duck; a mantis hunting an insect may itself be set upon by a sparrow.\n  Machinations are hidden within machinations; changes arise beyond changes. So how can wit and cleverness be relied upon?\n \u0026ndash; Back to Beginnings, Reflections on the Tao by Huanchu Daoren, translated by Thomas Cleary. They were written around 1600 by a retired Chinese Scholar, Hong Yingming, whose Taoist name, Huanchu Daoren, means ‚ÄúA Wayfarer Back to Beginnings.‚Äù\n","permalink":"https://www.thd.codes/posts/machinations/","summary":"An interesting quote about the unexpected effects of actions and the limitations of rationality and the planning fallacy:\n A net set up to catch fish may snare a duck; a mantis hunting an insect may itself be set upon by a sparrow.\n  Machinations are hidden within machinations; changes arise beyond changes. So how can wit and cleverness be relied upon?\n \u0026ndash; Back to Beginnings, Reflections on the Tao by Huanchu Daoren, translated by Thomas Cleary.","title":"Machinations"},{"content":"The Collatz Conjecture is a simple mathematical problem that still has no formal proof. So it\u0026rsquo;s an open problem.\nThis is how it works:\nChoose any positive integer x. While x \u0026gt; 0, do: if x is even, divide it by 2 (x = x/2) if x is odd, multiply it by 3 and add 1 (x = 3x + 1) The Collatz Conjecture states that no matter what value of x you start with, the sequence will always reach x = 1.\nExample:\nIf x = 10, you get the following sequence: [10, 5, 16, 8, 4, 2, 1].\nIf x = 77, you get the following collatz sequence: [77, 232, 116, 58, 29, 88, 44, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1].\nIn other words, it doesn\u0026rsquo;t matter the initial value you pick for x, you always end up going back to x = 1.\nA ruby implementation would look like this:\ndef collatz n seq = [n] until n == 1 n = (n.even?) ? (n / 2) : (3 * n + 1) seq \u0026lt;\u0026lt; n end seq end A Haskell implementation could look like this:\nchain :: (Integral a) =\u0026gt; a -\u0026gt; [a] chain 0 = error \u0026#34;Invalid!\u0026#34; chain 1 = [1] chain x | even x = x:chain (x `div` 2) | odd x = x:chain (x*3 + 1) ","permalink":"https://www.thd.codes/posts/collatz-conjecture/","summary":"The Collatz Conjecture is a simple mathematical problem that still has no formal proof. So it\u0026rsquo;s an open problem.\nThis is how it works:\nChoose any positive integer x. While x \u0026gt; 0, do: if x is even, divide it by 2 (x = x/2) if x is odd, multiply it by 3 and add 1 (x = 3x + 1) The Collatz Conjecture states that no matter what value of x you start with, the sequence will always reach x = 1.","title":"Collatz Conjecture"},{"content":"I\u0026rsquo;ve been reading the book \u0026ldquo;The Utopia of Rules: On Technology, Stupidity, and the Secret Joys of Bureaucracy\u0026rdquo;, from David Graeber, and I want to share two interesting quotes about Bureaucracy:\n The body of officials actively engaged in a \u0026lsquo;public\u0026rsquo; office, along with the respective apparatus of material implements and the files, make up a \u0026lsquo;bureau.\u0026rsquo; In private enterprise, \u0026lsquo;the bureau\u0026rsquo; is often called \u0026lsquo;the office.\u0026rsquo; (\u0026hellip;) The idea that the bureau activities of the state are intrinsically different in character from the management of private economic offices is a continental European notion and, by way of contrast, is totally foreign to the American way.\n Max Weber - Economy and Society Yet the fact remains the United States is ‚Äî and for a well over a century has been ‚Äî a profoundly bureaucratic society. The reason it is so easy to overlook is because most American bureaucratic habits and sensibilities ‚Äî from the clothing to the language to the design of forms and offices ‚Äî emerged from the private sector. When novelists and sociologists described the \u0026ldquo;Organization Man,\u0026rdquo; or \u0026ldquo;the Man in the Gray Flannel Suit,\u0026rdquo; the soullessly conformist U.S. equivalent to the Soviet apparatchik, they were not talking about functionaries in the Department of Landmarks and Preservation or the Social Security administration ‚Äî they were describing corporate middle management. True, by that time, corporate bureaucrats were not actually being called bureaucrats. But they were still setting the standard for what administrative functionaries were supposed to be like.\n David Graeber","permalink":"https://www.thd.codes/posts/two-quotes-about-bureaucracy/","summary":"I\u0026rsquo;ve been reading the book \u0026ldquo;The Utopia of Rules: On Technology, Stupidity, and the Secret Joys of Bureaucracy\u0026rdquo;, from David Graeber, and I want to share two interesting quotes about Bureaucracy:\n The body of officials actively engaged in a \u0026lsquo;public\u0026rsquo; office, along with the respective apparatus of material implements and the files, make up a \u0026lsquo;bureau.\u0026rsquo; In private enterprise, \u0026lsquo;the bureau\u0026rsquo; is often called \u0026lsquo;the office.\u0026rsquo; (\u0026hellip;) The idea that the bureau activities of the state are intrinsically different in character from the management of private economic offices is a continental European notion and, by way of contrast, is totally foreign to the American way.","title":"Two Quotes About Bureaucracy"},{"content":"","permalink":"https://www.thd.codes/search/","summary":"search","title":"Search"}]